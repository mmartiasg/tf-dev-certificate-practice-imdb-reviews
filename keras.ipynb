{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = 10000\n",
    "MAX_LENGHT = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=NUM_WORDS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect data\n",
    "\n",
    "Train data is an array of integer indexes\n",
    "\n",
    "Label 1 for possitive and 0 for negative feelings towards the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# translate sentence to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = dict([(value, key) for key, value in imdb.get_word_index().items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([index_to_word[index] for index in train_data[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Approach using 1 hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "for s in train_data:\n",
    "    print(type(s))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(sentence, max_lenght):\n",
    "    if max_lenght:\n",
    "        return sentence[:max_lenght]\n",
    "    return sentence\n",
    "\n",
    "def onehot_v2(sentences, num_words, max_lenght):\n",
    "    \"\"\"\n",
    "        For each sentence I have a word index\n",
    "        4 7 43 314\n",
    "        then limit those words to max lenght\n",
    "        the last step is to place a 1 in the position of each word Index\n",
    "        the output will be a 10000 position array\n",
    "        the array goes from 0 so position 4 will be the 5th position of the array\n",
    "        0 0 0 1 0 0 1 0 0 0 0 0 .... (44)1 ... (315)1\n",
    "    \"\"\"\n",
    "    zeros_array = np.zeros((len(sentences), num_words))\n",
    "    for sentence_index, sentence in enumerate(sentences):\n",
    "        for word_index in padding(sentence, max_lenght=max_lenght):\n",
    "            zeros_array[sentence_index, word_index] = 1\n",
    "    \n",
    "    return zeros_array\n",
    "\n",
    "#padding was not working\n",
    "def onehot_v1(sentences, num_words, max_lenght):\n",
    "    \"\"\"\n",
    "        For each sentence I have a word index\n",
    "        4 7 43 314\n",
    "        then limit those words to max lenght\n",
    "        the last step is to place a 1 in the position of each word Index\n",
    "        the output will be a 10000 position array\n",
    "        the array goes from 0 so position 4 will be the 5th position of the array\n",
    "        0 0 0 1 0 0 1 0 0 0 0 0 .... (44)1 ... (315)1\n",
    "    \"\"\"\n",
    "    zeros_array = np.zeros((len(sentences), num_words))\n",
    "    for sentence_index, sentence in enumerate(padding(sentences, max_lenght=max_lenght)):\n",
    "        for word_index in sentence:\n",
    "            zeros_array[sentence_index, word_index] = 1\n",
    "    \n",
    "    return zeros_array\n",
    "\n",
    "def onehot_v2(sentences, num_words, max_lenght):\n",
    "    \"\"\"\n",
    "        For each sentence I have a word index\n",
    "        4 7 43 314\n",
    "        then limit those words to max lenght\n",
    "        the last step is to place a 1 in the position of each word Index\n",
    "        the output will be a 10000 position array\n",
    "        the array goes from 0 so position 4 will be the 5th position of the array\n",
    "        0 0 0 1 0 0 1 0 0 0 0 0 .... (44)1 ... (315)1\n",
    "    \"\"\"\n",
    "    zeros_array = np.zeros((len(sentences), num_words))\n",
    "    for sentence_index, sentence in enumerate(sentences):\n",
    "        for word_index in padding(sentence, max_lenght=max_lenght):\n",
    "            zeros_array[sentence_index, word_index] = 1\n",
    "    \n",
    "    return zeros_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_train_data = onehot_v2(train_data, max_lenght=MAX_LENGHT, num_words=NUM_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 is reserved for the UKN token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_test_data = onehot_v2(test_data, max_lenght=MAX_LENGHT, num_words=NUM_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_test_label = np.array(test_labels, dtype=\"float32\")\n",
    "one_hot_train_label = np.array(train_labels, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 194, 1153, 194, 8255]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding(train_data[1], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 194, 1153, 194, 8255]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug padding was not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_v1([train_data[1]], NUM_WORDS, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_v2([train_data[1]], NUM_WORDS, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 64.00 GB\n",
      "maxCacheSize: 24.00 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 11:41:42.442971: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-05 11:41:42.443119: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "X_inputs = tf.keras.Input(shape=(NUM_WORDS))\n",
    "X = tf.keras.layers.Dense(units=32, activation=\"relu\")(X_inputs)\n",
    "X = tf.keras.layers.Dense(units=16, activation=\"relu\")(X_inputs)\n",
    "X = tf.keras.layers.Dense(units=8, activation=\"relu\")(X_inputs)\n",
    "X = tf.keras.layers.Dense(units=4, activation=\"relu\")(X_inputs)\n",
    "X_output = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(X)\n",
    "\n",
    "model=tf.keras.Model(inputs=X_inputs, outputs=X_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matiasgonzalez/miniforge3/envs/tf_2_9_metal_0_5_keras/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.RMSprop(lr=1e-3),\n",
    "                metrics=[\"accuracy\", \"Precision\", \"Recall\", \"AUC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience = 5\n",
    "            )\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < 15:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.05)\n",
    "\n",
    "learning_rate_exp_reduce = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(save_best_only=True, filepath=\"checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 11:41:43.126071: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-01-05 11:41:43.428599: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 0.6066 - accuracy: 0.6785 - precision: 0.6792 - recall: 0.6766 - auc: 0.7489"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 11:41:56.269310: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "782/782 [==============================] - 22s 27ms/step - loss: 0.6066 - accuracy: 0.6785 - precision: 0.6792 - recall: 0.6766 - auc: 0.7489 - val_loss: 0.5620 - val_accuracy: 0.7072 - val_precision: 0.7101 - val_recall: 0.7001 - val_auc: 0.7852 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/500\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5116 - accuracy: 0.7513 - precision: 0.7439 - recall: 0.7665 - auc: 0.8300INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "782/782 [==============================] - 18s 24ms/step - loss: 0.5115 - accuracy: 0.7513 - precision: 0.7439 - recall: 0.7665 - auc: 0.8300 - val_loss: 0.5413 - val_accuracy: 0.7188 - val_precision: 0.7206 - val_recall: 0.7145 - val_auc: 0.7985 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/500\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.4763 - accuracy: 0.7688 - precision: 0.7603 - recall: 0.7850 - auc: 0.8531 - val_loss: 0.5497 - val_accuracy: 0.7170 - val_precision: 0.7401 - val_recall: 0.6690 - val_auc: 0.8002 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/500\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.4583 - accuracy: 0.7824 - precision: 0.7763 - recall: 0.7936 - auc: 0.8649 - val_loss: 0.5524 - val_accuracy: 0.7184 - val_precision: 0.6994 - val_recall: 0.7658 - val_auc: 0.7996 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/500\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.4463 - accuracy: 0.7906 - precision: 0.7828 - recall: 0.8043 - auc: 0.8728 - val_loss: 0.5551 - val_accuracy: 0.7196 - val_precision: 0.7189 - val_recall: 0.7211 - val_auc: 0.7996 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/500\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.4367 - accuracy: 0.7967 - precision: 0.7897 - recall: 0.8086 - auc: 0.8788 - val_loss: 0.5588 - val_accuracy: 0.7194 - val_precision: 0.7118 - val_recall: 0.7372 - val_auc: 0.7989 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/500\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.4291 - accuracy: 0.8009 - precision: 0.7944 - recall: 0.8119 - auc: 0.8835 - val_loss: 0.5714 - val_accuracy: 0.7137 - val_precision: 0.7385 - val_recall: 0.6618 - val_auc: 0.7976 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28ee85f00>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(one_hot_train_data,\n",
    "         one_hot_train_label,\n",
    "         epochs=500,\n",
    "         validation_data=(one_hot_test_data, one_hot_test_label),\n",
    "         callbacks=[early_stop, learning_rate_exp_reduce, model_checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2_9_metal_0_5_keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a15c967ccfdd413fdaae9b0ef29591898e7727afbc71b52356c7c116ffefefea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
